{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
        "outputId": "95587e83-1f52-4ca6-c756-8a6d5a7d248e"
      },
      "outputs": [],
      "source": [
        "# Use termcolor to make it easy to colorize the outputs.\n",
        "!pip install termcolor > /dev/null\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain_experimental\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu==1.7.4\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List\n",
        "import math\n",
        "import faiss\n",
        "import os\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from termcolor import colored\n",
        "from langchain_experimental.generative_agents import (\n",
        "\n",
        "    GenerativeAgent,\n",
        "    GenerativeAgentMemory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p_RduA0AW2FK",
      "metadata": {
        "id": "p_RduA0AW2FK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81824e76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81824e76",
        "outputId": "f58890ec-57a3-4901-8f0a-5e42e0af9a6a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "USER_NAME = \"\"  # The name you want to use when interviewing the agent.\n",
        "\n",
        "LLM = ChatOpenAI(max_tokens=1500)  # Can be any LLM you want."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa3ca02",
      "metadata": {
        "id": "2fa3ca02"
      },
      "source": [
        "## Implementing Your First Generative Agent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
      "metadata": {
        "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def relevance_score_fn(score: float) -> float:\n",
        "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
        "    # This will differ depending on a few things:\n",
        "    # - the distance / similarity metric used by the VectorStore\n",
        "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
        "    # This function converts the euclidean norm of normalized embeddings\n",
        "    # (0 is most similar, sqrt(2) most dissimilar)\n",
        "    # to a similarity function (0 to 1)\n",
        "    return 1.0 - score / math.sqrt(2)\n",
        "\n",
        "\n",
        "def create_new_memory_retriever():\n",
        "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
        "    # Define your embedding model\n",
        "    embeddings_model = OpenAIEmbeddings()\n",
        "    # Initialize the vectorstore as empty\n",
        "    embedding_size = 1536\n",
        "    index = faiss.IndexFlatL2(embedding_size)\n",
        "    vectorstore = FAISS(\n",
        "        embeddings_model.embed_query,\n",
        "        index,\n",
        "        InMemoryDocstore({}),\n",
        "        {},\n",
        "        relevance_score_fn=relevance_score_fn,\n",
        "    )\n",
        "    return TimeWeightedVectorStoreRetriever(\n",
        "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
        "outputId": "742bf4fd-9175-43af-ba2c-697aa965d4c3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "alexis_memory = GenerativeAgentMemory(\n",
        "    llm=LLM,\n",
        "    memory_retriever=create_new_memory_retriever(),\n",
        "    verbose=False,\n",
        "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
        ")\n",
        "\n",
        "# Defining the Generative Agent: Alexis\n",
        "alexis = GenerativeAgent(\n",
        "    name=\"Alexis\",\n",
        "    age=30,\n",
        "    traits=\"curious, creative writer, world traveler\",  # Persistent traits of Alexis\n",
        "    status=\"exploring the intersection of technology and storytelling\",  # Current status of Alexis\n",
        "    memory_retriever=create_new_memory_retriever(),\n",
        "    llm=LLM,\n",
        "    memory=alexis_memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c524d529",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c524d529",
        "outputId": "b352d8d3-23f7-4aca-9774-f7cc4929feb0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# The current \"Summary\" of a character can't be made because the agent hasn't made\n",
        "# any observations yet.\n",
        "print(alexis.get_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
        "outputId": "787d4075-14e9-46ec-e2a8-04dd952809bf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# We can add memories directly to the memory object\n",
        "\n",
        "alexis_observations = [\n",
        "    \"Alexis recalls her morning walk in the park\",\n",
        "    \"Alexis feels excited about the new book she started reading\",\n",
        "    \"Alexis remembers her conversation with a close friend\",\n",
        "    \"Alexis thinks about the painting she saw at the art gallery\",\n",
        "    \"Alexis is planning to learn a new recipe for dinner\",\n",
        "    \"Alexis is looking forward to her weekend trip\",\n",
        "    \"Alexis contemplates her goals for the month.\"\n",
        "]\n",
        "\n",
        "for observation in alexis_observations:\n",
        "    alexis.memory.add_memory(observation)\n",
        "\n",
        "\n",
        "\n",
        "# We will see how this summary updates after more observations to create a more rich description.\n",
        "print(alexis.get_summary(force_refresh=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pr2_MJggZcve",
      "metadata": {
        "id": "Pr2_MJggZcve"
      },
      "source": [
        "## Interacting and Providing Context to Generative Characters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
      "metadata": {
        "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
        "tags": []
      },
      "source": [
        "## Pre-Interview with Character\n",
        "\n",
        "Before sending our character on their way, let's ask them a few questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf125d8-f54c-4c5f-b6af-32789b1f7d3a",
      "metadata": {
        "id": "eaf125d8-f54c-4c5f-b6af-32789b1f7d3a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
        "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
        "    new_message = f\"{USER_NAME} says {message}\"\n",
        "    return agent.generate_dialogue_response(new_message)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
        "outputId": "5ba18969-db68-455a-bc21-51c7607ae66b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "interview_agent(alexis, \"What do you like to do?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
      "metadata": {
        "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea"
      },
      "source": [
        "## Step through the day's observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
      "metadata": {
        "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Let's give Alexis a series of observations to reflect on her day\n",
        "# Adding observations to Alexis' memory\n",
        "alexis_observations_day = [\n",
        "    \"Alexis starts her day with a refreshing yoga session.\",\n",
        "    \"Alexis spends time writing in her journal.\",\n",
        "    \"Alexis experiments with a new recipe she found online.\",\n",
        "    \"Alexis gets lost in her thoughts while gardening.\",\n",
        "    \"Alexis decides to call her grandmother for a heartfelt chat.\",\n",
        "    \"Alexis relaxes in the evening by playing her favorite piano pieces.\",\n",
        "]\n",
        "\n",
        "for observation in alexis_observations_day:\n",
        "    alexis.memory.add_memory(observation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
        "outputId": "eb5c9ae0-b2b0-4d01-bc55-15024a526452",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Let's observe how Alexis's day influences her memory and character\n",
        "for i, observation in enumerate(alexis_observations_day):\n",
        "    _, reaction = alexis.generate_reaction(observation)\n",
        "    print(colored(observation, \"green\"), reaction)\n",
        "    if ((i + 1) % len(alexis_observations_day)) == 0:\n",
        "        print(\"*\" * 40)\n",
        "        print(\n",
        "            colored(\n",
        "                f\"After these observations, Alexis's summary is:\\n{alexis.get_summary(force_refresh=True)}\",\n",
        "                \"blue\",\n",
        "            )\n",
        "        )\n",
        "        print(\"*\" * 40)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
